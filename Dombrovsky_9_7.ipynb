{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\wsluvv\\Downloads\\ПР_МН_9\\ПР_МН_9\\Dombrovsky_9_7.ipynb Cell 1\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/wsluvv/Downloads/%D0%9F%D0%A0_%D0%9C%D0%9D_9/%D0%9F%D0%A0_%D0%9C%D0%9D_9/Dombrovsky_9_7.ipynb#W0sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtf\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/wsluvv/Downloads/%D0%9F%D0%A0_%D0%9C%D0%9D_9/%D0%9F%D0%A0_%D0%9C%D0%9D_9/Dombrovsky_9_7.ipynb#W0sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/wsluvv/Downloads/%D0%9F%D0%A0_%D0%9C%D0%9D_9/%D0%9F%D0%A0_%D0%9C%D0%9D_9/Dombrovsky_9_7.ipynb#W0sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyplot\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mplt\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 10\n",
    "num_features = 784\n",
    "learning_rate = 0.001\n",
    "training_steps = 3000\n",
    "batch_size = 256\n",
    "display_step = 100\n",
    "n_hidden_1 = 128\n",
    "n_hidden_2 = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\wsluvv\\Downloads\\ПР_МН_9\\ПР_МН_9\\Dombrovsky_9_7.ipynb Cell 3\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/wsluvv/Downloads/%D0%9F%D0%A0_%D0%9C%D0%9D_9/%D0%9F%D0%A0_%D0%9C%D0%9D_9/Dombrovsky_9_7.ipynb#W2sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdatasets\u001b[39;00m \u001b[39mimport\u001b[39;00m mnist\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/wsluvv/Downloads/%D0%9F%D0%A0_%D0%9C%D0%9D_9/%D0%9F%D0%A0_%D0%9C%D0%9D_9/Dombrovsky_9_7.ipynb#W2sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m (x_train, y_train), (x_test, y_test) \u001b[39m=\u001b[39m mnist\u001b[39m.\u001b[39mload_data()\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/wsluvv/Downloads/%D0%9F%D0%A0_%D0%9C%D0%9D_9/%D0%9F%D0%A0_%D0%9C%D0%9D_9/Dombrovsky_9_7.ipynb#W2sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m x_train, x_test \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(x_train, np\u001b[39m.\u001b[39mfloat32), np\u001b[39m.\u001b[39marray(x_test, np\u001b[39m.\u001b[39mfloat32)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = np.array(x_train, np.float32), np.array(x_test, np.float32)\n",
    "x_train, x_test = x_train.reshape([-1, num_features]), x_test.reshape([-1, num_features])\n",
    "x_train, x_test = x_train / 255., x_test / 255.\n",
    "train_data = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "train_data = train_data.repeat().shuffle(5000).batch(batch_size).prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseLayer(tf.Module):\n",
    "    def __init__(self, in_features, out_features, name=None):\n",
    "        super().__init__(name=name)\n",
    "        self.w = tf.Variable(\n",
    "            tf.random.normal([in_features, out_features]), name=\"w\"\n",
    "        )\n",
    "        self.b = tf.Variable(tf.zeros([out_features]), name=\"b\")\n",
    "\n",
    "    def __call__(self, x, activation=0):\n",
    "        y = tf.matmul(x, self.w) + self.b\n",
    "        if activation != 0:\n",
    "            return tf.nn.softmax(y)\n",
    "        else:\n",
    "            return tf.nn.sigmoid(y)\n",
    "\n",
    "class NN(tf.Module):\n",
    "  def __init__(self, name=None):\n",
    "    super().__init__(name=name)\n",
    "    self.layer_1 = DenseLayer(in_features=num_features, out_features=n_hidden_1)\n",
    "    self.layer_2 = DenseLayer(in_features=n_hidden_1, out_features=n_hidden_2)\n",
    "    self.layer_3 = DenseLayer(in_features=n_hidden_2, out_features=num_classes)\n",
    "\n",
    "  def __call__(self, x):\n",
    "    \n",
    "    x1 = self.layer_1(x, activation=0)\n",
    "    x2 = self.layer_2(x1, activation=0)\n",
    "    x3 = self.layer_3(x2, activation=1)\n",
    "\n",
    "    return x3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy(y_pred, y_true):\n",
    "\n",
    "    y_true = tf.one_hot(y_true, depth=num_classes)\n",
    "\n",
    "    y_pred = tf.clip_by_value(y_pred, 1e-9, 1.)\n",
    "\n",
    "    return tf.reduce_mean(-tf.reduce_sum(y_true * tf.math.log(y_pred)))\n",
    "\n",
    "def accuracy(y_pred, y_true):\n",
    "    acc = tf.metrics.Accuracy()\n",
    "    acc.update_state(y_true, tf.argmax(y_pred, axis=1))\n",
    "    return acc.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neural_net = NN(name=\"mnist\")\n",
    "def train(nn, input_x, output_y):\n",
    "  optimizer = tf.optimizers.SGD(learning_rate)\n",
    "  with tf.GradientTape() as g:\n",
    "    pred = neural_net(input_x)\n",
    "    loss = cross_entropy(pred, output_y)\n",
    "    trainable_variables = nn.trainable_variables\n",
    "    gradients = g.gradient(loss, trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_history = []\n",
    "accuracy_history = []\n",
    "for step, (batch_x, batch_y) in enumerate(train_data.take(training_steps)):\n",
    "    train(neural_net, batch_x, batch_y)\n",
    "    \n",
    "    if step % display_step == 0:\n",
    "        pred = neural_net(batch_x)\n",
    "        current_loss = cross_entropy(pred, batch_y)\n",
    "        loss_history.append(current_loss)\n",
    "        current_accuracy = accuracy(pred, batch_y)\n",
    "        accuracy_history.append(current_accuracy)\n",
    "        print(f\"Step: {step}, Loss: {current_loss}, Accuracy: {current_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "fig, axs = plt.subplots(figsize=(16, 10))\n",
    "axs.plot(loss_history, 'r', label='loss', linestyle=\":\")\n",
    "axs.legend()\n",
    "axs2=axs.twinx()\n",
    "axs2.plot(accuracy_history, 'b', label='accuracy', linestyle=\":\")\n",
    "plt.legend()\n",
    "plt.title('Залежності зміни точності та втрат від кроку', fontsize=20, color='g')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neural_net_accuracy = accuracy(neural_net(x_train), y_train)\n",
    "print(f\"Accuracy: {neural_net_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\wsluvv\\Downloads\\ПР_МН_9\\ПР_МН_9\\Dombrovsky_9_7.ipynb Cell 10\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/wsluvv/Downloads/%D0%9F%D0%A0_%D0%9C%D0%9D_9/%D0%9F%D0%A0_%D0%9C%D0%9D_9/Dombrovsky_9_7.ipynb#X12sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m test_img \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mpermutation(x_test\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m])[:\u001b[39m10\u001b[39m]\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/wsluvv/Downloads/%D0%9F%D0%A0_%D0%9C%D0%9D_9/%D0%9F%D0%A0_%D0%9C%D0%9D_9/Dombrovsky_9_7.ipynb#X12sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m y_test_true \u001b[39m=\u001b[39m y_test[test_img]\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/wsluvv/Downloads/%D0%9F%D0%A0_%D0%9C%D0%9D_9/%D0%9F%D0%A0_%D0%9C%D0%9D_9/Dombrovsky_9_7.ipynb#X12sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m pred_data \u001b[39m=\u001b[39m [np\u001b[39m.\u001b[39margmax(x) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m neural_net(x_test[test_img])]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "test_img = np.random.permutation(x_test.shape[0])[:10]\n",
    "y_test_true = y_test[test_img]\n",
    "pred_data = [np.argmax(x) for x in neural_net(x_test[test_img])]\n",
    "plt.figure(figsize=(16, 6))\n",
    "for i in range(10):\n",
    "    print(f\"True: {y_test_true[i]} Predict: {pred_data[i]} {True if y_test_true[i] - pred_data[i] == 0 else False}\")\n",
    "    plt.subplot(1, 10, (i + 1))\n",
    "    plt.imshow(x_test[test_img[i]].reshape(28, 28), cmap='gray')\n",
    "    plt.text(x=10, y=-10, s=pred_data[i], fontsize=18)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Код реалізує просту нейронну мережу для класифікації зображень рукописних цифри набору даних MNIST. \n",
    "Мережа використовує два приховані шари та функцію активації softmax в останньому шарі для визначення ймовірностей класів.\n",
    "\n",
    "Після навчання модельі на екран виводиться графік покрокової зміни втрати і точності для визначення динаміки навчання. Н\n",
    "а графіку видно, що модель навчається і покращується в міру збільшення числа кроків.\n",
    "\n",
    "Далі виводяться 10 випадкових зображень з тестового набору, а також правильні та передбачені класи. \n",
    "Аналіз результатів показує, що більшість класифікацій вірні модель працює добре.\n",
    "\n",
    "У цілому код демонструє ефективність нейронної мережі за завданням класифікації рукописних чисел, \n",
    "Вихідні дані дають важливе уявлення про її роботу."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
